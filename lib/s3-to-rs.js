/**
 * Created by teklof on 30.1.15.
 */
var _ = require('lodash');
var util = require('util');
var ut = require('./utils');
var Promise = require('bluebird');
var debug = require('debug')('s4qs-rs:s3-to-rs');
var error = require('debug')('s4qs-rs:s3-to-rs:error');
error.log = console.error;
var LRU = require('lru-cache');
var mup = require('./manifest-uploader');
var Uploader = mup.Uploader;
var inspect = _.partialRight(util.inspect, {depth: 10});

/**
 * S3Copier polls SQS for S3 object creation events and uses COPY to copy the S3 object data to Redshift.
 *
 * Don't forget to provide credentials in copyParams.
 *
 * @param {Object} s3 Initialized AWS S3 service object
 * @param {Object} pg Postgres module
 * @param {Object} rs Initialized AWS Redshift service object
 * @param {String} copyParams.schema Schema name to use
 * @param {String|Function} copyParams.table String with name of table to COPY to, or a function that takes an
 * S3 URI and returns a table name
 * @param {Array} copyParams.args Array of strings to be given as parameterless arguments to COPY. For example
 * ['GZIP', 'TRUNCATECOLUMNS']
 * @param {Object} copyParams.withParams Object with parametrized COPY arguments. For example
 * {'TIMEFORMAT': 'auto', 'NULL': 'null'}
 * @param {Object} poller SQS poller
 * @param {Number} options.pollIntervalSeconds Interval between SQS polls
 * @param {String} options.connStr Connection string for Redshift
 * @param {String} options.tablePostfix Added to the end of the table name generated by
 * copyParams.table. Handy for having different tables based on NODE_ENV
 * @param {Number} options.clusterAvailCheckInterval Check cluster status at clusterAvailCheckInterval ms intervals.
 * If the cluster is not available, SQS polling and manifest uploading will be stopped.
 * @param {Object} options.manifestUploader Manifest uploader options. See ./manifest-uploader.js for details.
 *
 * @param {Object} options.timeSeries Time series table configuration
 * @param {Number} options.timeSeries.period Time series table period in seconds. I.e. a value of 3600 would mean
 * a new time series table is created per every hour
 * @param {Number} options.timeSeries.maxTables Keep a maximum of maxTables time series tables. Oldest tables will be
 * deleted
 * @param {String} options.timeSeries.latestPostfix if this is set, use table name + this postfix to create a view
 * to the latest time series table
 * @param {Object} options.timeSeries.tableDef Time series table DDL etc.
 * @param {Array} options.timeSeries.tableDef.columns Array of column definitions like ["source int not null encode bytedict",
 * "campaign char(24) encode bytedict", "..."]
 * @param {Array} options.timeSeries.tableDef.tableAttrs Array of table attributes like ["DISTKEY(ID)", "SORTKEY(TS)"]
 * @constructor
 * @type {S3Copier}
 */
var S3Copier = exports.S3Copier = function S3Copier(poller, pg, s3, rs, copyParams, options) {
  if(!options) {
    throw new Error("Missing options");
  }

  if(!pg) {
    throw new Error("Missing PostgreSQL module");
  }

  if(!poller) {
    throw new Error("Missing poller");
  }

  if(!options.Redshift.connStr) {
    throw new Error("missing connection string");
  }

  if(!options.Redshift.params.ClusterIdentifier) {
    throw new Error("missing options.Redshift.params.ClusterIdentifier");
  }

  if(!options.manifestUploader) {
    throw new Error("missing manifest uploader options");
  }

  if(!rs) {
    throw new Error("Missing Redshift service");
  }

  if(!s3) {
    throw new Error("Missing S3 service")
  }

  if(!options.timeSeries) {
    throw new Error("Missing time series options");
  }

  var table = copyParams.table;
  if(!_.isString(table) && !_.isFunction(table)) {
    throw new Error("copyParams.table must be a string or function");
  }

  var _tableNamer;

  if(_.isString(table)) {
    _tableNamer = ut.tableStrToNamer(table);
  } else {
    _tableNamer = table;
  }

  this._pollIntervalS = options.pollIntervalSeconds || 60;

  this._availCheckInterval = options.Redshift.clusterAvailCheckInterval || -1;

  if(options.tablePostfix) {
    debug("Table postfix " + options.tablePostfix);
  }

  this._tablePostfix = options.tablePostfix || "";

  if(copyParams.args) {
    copyParams.args = [];
  }

  copyParams.args.push("MANIFEST");

  this._pg = pg;
  this._connStr = options.Redshift.connStr;
  this._copyTemplate = _copyParamsTempl(copyParams);
  this._poller = poller;
  this._rs = Promise.promisifyAll(rs);
  this.started = false;
  this._timeout = null; // used for SQS poller setTimeout obj
  this._availChk = null; // used for cluster availability check interval


  // if an _onMsg call is running, this'll contain an object with properties that'll be fulfilled when the messages
  // have been handled. Keys will be table names
  this._manifestsPending = {};
  var lruOpts = options.LRU || {max: 1000};
  this._seenMsgs = LRU(lruOpts);

  // since _tableNamer takes an S3 URI and turns it into a table name, we can use it as the manifest uploader's grouper
  this._uploader = new Uploader(s3, _.merge(options.manifestUploader, {grouper: _tableNamer}));

  this._usingPg = function(fn) {
    return Promise.using(ut.getPgClient(this._pg, this._connStr), fn);
  }.bind(this);

  poller.on('error', function (err) {
    error("SQS poller error: " + err + ". Stopping");
    this.stop(true);
  }.bind(this));

  this._tsMgr = new TimeSeriesManager(this._usingPg, copyParams.schema, this._tablePostfix, options.timeSeries);

};

S3Copier.prototype._connAndCopy = function _connAndCopy(s3URI, table) {
  var self = this;
  return this._usingPg(function (client) {
    var query = util.format(self._copyTemplate, table, s3URI);
    return client.queryAsync(query).return(s3URI);
  });

};

S3Copier.prototype._markSeen = function(msgs) {
  var self = this;
  _.each(msgs, function (msg) {
    self._seenMsgs.set(msg.MessageId, true);
  });
};

S3Copier.prototype._dedup = function(msgs) {
  var self = this;
  return new Promise(function (resolve) {
    var grouped = _.groupBy(msgs, function (msg) {
      return !!self._seenMsgs.get(msg.MessageId); // bang bang to coerce undefined into a bool
    }); // {true: [duplicates], false: [nondups]}

    var dups = grouped.true || [];
    var nonDups = grouped.false || [];

    if (dups.length > 0) {
      error("Found " + dups.length + " duplicate messages. Deleting");
      resolve(self._poller.deleteMsgs(dups)
        .catch(function (err) {
          error("Error deleting duplicates: " + err);
        })
        .tap(function() {
          debug("Duplicates deleted");
        })
        .return(nonDups))
      ;
    } else {
      resolve(nonDups);
    }

  });
};

S3Copier.prototype._delete = function(msgs) {
  debug("Deleting " + msgs.length + " messages");
  return this._poller.deleteMsgs(msgs)
    .catch(function (err) {
      error("Error deleting messages: " + err);
    })
    .tap(function () {
      debug("Messages deleted");
    });
};


S3Copier.prototype._onManifest = function _onManifest(manif) {
  debug("Handling manifest " + manif.manifestURI + " for base table " + manif.table);

  var promise = this._tsMgr.tsTableFor(manif.table).bind(this)
      .then(function (table) {
        debug("Copying " + manif.manifestURI + " to " + table);
        return this._connAndCopy(manif.manifestURI, table).bind(this)
          .then(function (uri) {
            debug("Manifest " + uri + " copied");
            return this._delete(manif.msgs).catch(function () {
              error("Couldn't delete messages for manifest " + manif.manifestURI)
            });
          })
          .catch(function (err) {
            error("Error copying manifest " + manif.manifestURI + ": " + err);
          })
          .then(function () {
            return manif.delete().catch(function (err) {
              error("Couldn't delete manifest " + manif.manifestURI + ": " + err);
            });
          })
          .return(manif);
      })
      .catch(function (err) {
        error("Error getting time series table: " + err);
        return manif.delete().catch(function (err) {
          error("Couldn't delete manifest " + manif.manifestURI + ": " + err);
        });
      })
    ;

  if(this._manifestsPending[manif.table] && this._manifestsPending[manif.table].isPending()) {
    error("Already have a pending manifest upload for table " + manif.table + this._tablePostfix + "? Joining it anyhow");
    promise = Promise.join(promise, this._manifestsPending[manif.table]);
  }
  this._manifestsPending[manif.table] = promise;

};

S3Copier.prototype._onMsgs = function _onMsgs(msgs) {
  debug("Got " + msgs.length + " messages");
  var nextPoll = Date.now() + this._pollIntervalS * 1000
    , self = this
    ;

  return new Promise(function (resolve) {
    if(msgs.length == 0) {
      debug("No messages, scheduling new poll.");
      self._schedulePoll(nextPoll);
      resolve();
      return;
    }

    resolve(self._dedup(msgs).then(function(nondups) {
      self._uploader.addMessages(nondups);
      self._schedulePoll(nextPoll);
    }));
  });
};

S3Copier.prototype._schedulePoll = function(nextPoll) {
  if(!this.started) {
    return;
  }

  var timeLeft = nextPoll - Date.now();

  if(timeLeft < 0) {
    timeLeft = 0;
  }
  debug("Seconds until next poll: " + timeLeft / 1000);
  this._timeout = setTimeout(this._poller.poll.bind(this._poller) , timeLeft);
};

/**
 * Stop the S3Copier. Returns a promise that'll be resolved once all underway COPYs are done.
 * @param {Boolean} checkAvail If true, don't stop the cluster availability checker.
 * @return {*}
 */
S3Copier.prototype.stop = function(checkAvail) {
  if(this.started) {
    // set this so that if _availHandler is waiting for its promise it won't try to start S3Copier again when it sees
    // it isn't started.
    this._reallyStop = !checkAvail;
    this.started = false;

    debug("Stopping. checkAvail " + checkAvail);

    this._uploader.removeAllListeners("manifest");
    this._poller.removeAllListeners("messages");
    this._uploader.stop();
    clearTimeout(this._timeout);

    if(!checkAvail) {
      clearInterval(this._availChk);
    }
  }

  if(this._numPending() > 0) {
    debug("Manifests pending for " + this._numPending() + " group(s). Waiting for them to finish");
    return Promise.props(this._manifestsPending);
  }

  return Promise.resolve({});
};

S3Copier.prototype._numPending = function _numPending() {
  return _.reduce(this._manifestsPending, function (acc, val) {
    return acc + (val.isPending() ? 1 : 0);
  }, 0);
};

S3Copier.prototype._availHandler = function _availHandler() {
  debug("Checking cluster availability");
  this._isClusterAvail()
    .bind(this)
    .then(function (avail) {
      if (!avail) {
        if (this.started) {
          error("_availHandler: cluster went unavailable, stopping");
          return this.stop(true);
        } else {
          return Promise.resolve();
        }
      } else { // cluster available
        if (!this.started && !this._reallyStop) {
          error("_availHandler: cluster became available, starting");
          return this.start(true);
        } else {
          return Promise.resolve();
        }
      }
    });
};

S3Copier.prototype._isClusterAvail = function _isClusterAvail() {
  return this._rs.describeClustersAsync()
    .then(function (res) {
      if (res.Clusters.length != 1) {
        throw new Error("DescribeClusters got " + res.Clusters.length + " results: did you forget to set " +
                        "Redshift.params.ClusterIdentifier?");
      }

      debug("ClusterStatus " + res.Clusters[0].ClusterStatus);
      return res.Clusters[0].ClusterStatus === "available";
    })
    .catch(function (err) {
      error("_isClusterAvail got " + err + " when trying to check cluster availability");
      return false;
    });
};

/**
 * Starts the S3Copier
 * @param {Boolean} skipAvailCheck if skipAvailCheck is true, skip cluster availability check and just start.
 */
S3Copier.prototype.start = function start(skipAvailCheck) {
  if (!this.started) {
    return (skipAvailCheck ? Promise.resolve(true) : this._isClusterAvail())
      .bind(this)
      .then(function (avail) {
        if (avail) {
          debug("Cluster available, starting");
          this._uploader.start();
          this._poller.on('messages', this._onMsgs.bind(this));
          this._uploader.on('manifest', this._onManifest.bind(this));
          this._poller.poll();
          this.started = true;
        } else {
          error("Cluster unavailable, can't start yet");
          if (this._availCheckInterval < 0) {
            throw new Error("Cluster unavailable and no clusterAvailCheckInterval configured, bailing out");
          }
        }

        if (this._availCheckInterval > 0 && !this._availChk) {
          this._availChk = setInterval(this._availHandler.bind(this), this._availCheckInterval * 1000);
        }
      });
  }

  return Promise.resolve();
};

var _boolish = /^(true|on|false|off)$/i;
var _enc = /^encoding$/i;

var _copyParamsTempl = exports._copyParamsTempl = function _copyParamsTempl(copyParams) {

  copyParams.withParams = copyParams.withParams || {};
  copyParams.args = copyParams.args || [];

  var withp = _.reduce(_.pairs(copyParams.withParams), function (acc, pair) {
    var key = pair[0]
      , value = pair[1];
    if (!(_.isNumber(value) || value.toString().match(_boolish) || key.match(_enc))) {
      // we need quotes since value is not a number or boolean-ish, and the key isn't "encoding"
      value = "'" + value + "'";
    }
    acc.push(key + " " + value);

    return acc;

  }, []);

  return "COPY %s FROM '%s' " + copyParams.args.concat(withp).join(' ') + ";";
};

/**
 * Creates new time series tables if needed, creates views for the tables, and deletes old tables.
 * @param {Function} usingPgFn A function that takes another function which will be called with a promisified Postgres client
 * and returns a promise of a result
 * @param {String} postfix A table postfix to be added to the base name _before_ the time series postfix.
 * @constructor
 */
var TimeSeriesManager = exports.TimeSeriesManager = function TimeSeriesManager(usingPgFn, schema, postfix, options) {

  if(!_.isString(postfix)) {
    throw new Error("postfix not a string");
  }

  if(!schema) {
    throw new Error("missing schema");
  }

  if(!_.isFunction(usingPgFn)) {
    throw new Error("Postgres client getter not a function");
  }

  if(!options) {
    throw new Error("no options");
  }

  this._options = options;

  this._schema = schema;

  this._postfix = postfix;

  this._usingPg = usingPgFn;
};

function isDuplicate(error) {
  return error && error.code === "42P07";
}

/**
 * Finds time series tables for a base name and returns them in a promise of an array
 * @param name base name
 * @return {Promise} promise of array of table names, sorted oldest first
 * @private
 */
TimeSeriesManager.prototype._listTsTables = function(name) {
  debug("_listTsTables " + name);

  return this._usingPg(function (client) {
    var queryStr = "select tablename from pg_tables where schemaname = $1" +
                   " and tablename like $2 || '_ts_%' order by tablename asc"
      , params = [this._schema, name + this._postfix]
      ;

    return client.queryAsync(queryStr, params)
      .then(function (res) {
        return _.pluck(res.rows, "tablename");
      });
  }.bind(this));
};

/**
 * Takes an array of table names and returns a promise for an object that has table names as keys and an alphabetically
 * sorted array of column names as their values.
 * @param {Array} tableNames Array of table names
 * @return {Promise} an object that has table names as keys and an alphabetically
 * @private
 */
TimeSeriesManager.prototype._columnsForTables = function(tableNames) {
  // pg and/or Redshift doesn't seem to handle arrays as parameters for IN queries, so we have to expand the table names
  // to $1, $2, $3, [...]
  var dollars = _.times(tableNames.length, function (n) {
    return "$" + (n + 1);
  }).join(", ");

  var query = util.format("select tablename, \"column\" from pg_table_def where tablename in (%s) " +
                          "and schemaname = $%d", dollars, tableNames.length+1);

  return this._usingPg(function (client) {
    return client.queryAsync(query, tableNames.concat(this._schema))
      .then(function(res) {
        // res.rows is an array like [{tablename: "table1", column: "column1"},
        // {tablename: "table1", column: "column2}, ...]. Group it by tablename, then turn the resulting object into
        // an object like {table1: ["column1", "column2", ...], table2: ["column1", ...]}
        return _(res.rows).groupBy("tablename").transform(function(acc, v, k) {
          acc[k] = _.pluck(v, "column");
        }).value();
      })
  }.bind(this));
};

/**
 * Takes a table name, array of its columns and an array with the set of column names, returns a SELECT statement
 * that has columns in alphabetical order and missing columns as NULLs.
 * @param {String} tableName source table name
 * @param {Array} tableCols Array of columns the table has
 * @param {Array} allCols Union of column names for all time series tables
 * @returns {String} select statement for table with columns in alphabetical order and missing columns as NULLs
 * @private
 */
TimeSeriesManager.prototype._selectFor = function _selectFor(tableName, tableCols, allCols) {

  // which columns is tableName missing
  var missing = _.difference(allCols, tableCols)
    , colList = _(missing)
      // turn missing and present columns into helpful objects
      .map(function (col) {
        return {col: col, missing: true}
      })
      .concat(_.map(tableCols, function (col) {
        return {col: col, missing: false}
      }))
      // sort 'em by the column name
      .sort(function compare(a, b) {
        if (a.col < b.col) return -1;
        if (a.col > b.col) return 1;
        return 0;
      })
      // turn 'em into strings
      .map(function (obj) {
        if (obj.missing) {
          return "NULL as " + obj.col
        }
        return obj.col;
      })
      .join(", ")
    ;

  return util.format("select %s from %s", colList, tableName);
};

TimeSeriesManager.prototype._dropTables = function(tables) {
  debug("Dropping tables " + tables);
  var query = "drop table if exists " + tables.join(",");
  return this._usingPg(function(client) {
    return client.queryAsync(query).return(tables);
  });
};

/**
 * Prunes time series tables if necessary. Will return the names of time series tables that were spared
 * @param {Array} tables Array of table names
 * @param {String} name Base table name
 * @return {Promise} promise of array of spared time series tables
 * @private
 */
TimeSeriesManager.prototype._pruneTsTables = Promise.method(function(name, tables) {
  debug("_pruneTsTables for " + tables.length + " tables");

  if(!tables.length) {
    return [];
  }

  var tsOpts = this._options[name];
  if(tables.length > tsOpts.maxTables) {
    var diff = tables.length - tsOpts.maxTables
      , toDrop = _.take(tables, diff)
      , left = _.takeRight(tables, tsOpts.maxTables)
      ;

    debug("Dropping " + diff + "/" + tables.length + " time series table(s) for "+ name + ". New amount " + left.length);
    return this._dropTables(toDrop).catch(function(err) {
      error("Error dropping " + toDrop.join(", ") + ": " + err);
    }).return(left);
  }
  return tables;
});

/**
 * Creates a rolling view that includes at most the configured amount of tables for a given base name. View
 * table count is set by the tablesInView property of the table's configuration.
 * @param {String} name base table name
 * @param {Array} tables array of table names
 * @returns {Promise} promise of table names (equal to tables parameter)
 * @private
 */
TimeSeriesManager.prototype._updateView = Promise.method(function(name, tables) {
  var opts = this._options[name];

  if(!opts) {
    throw new Error("No options for table " + name);
  }

  if(!tables.length) {
    return [];
  }

  var viewTables = _.takeRight(tables, opts.tablesInView || opts.maxTables)
    , columnMapP = this._columnsForTables(viewTables);

  return columnMapP.bind(this).then(function (columnMap) {
    return this._usingPg(function (client) {
      var viewName = name + "_view" + this._postfix;
      debug("Creating view " + viewName + " with " + viewTables.length + " tables (max " +
            (opts.tablesInView || opts.maxTables) + ")");
      // the set of all columns in all the tables
      var allCols = _.union.apply(null, _.values(columnMap))
        , selects = _.map(viewTables, function (table) {
          return this._selectFor(table, columnMap[table], allCols);
        }.bind(this)).join(" union all ");

      return Promise.using(ut.getTransaction(client), function (client) {
        var viewP = client.queryAsync(util.format("create view temp_%s as %s", viewName, selects))
          .then(function() {
            return client.queryAsync("drop view " + viewName);
          })
          .then(function () {
            return client.queryAsync(util.format("alter table temp_%s rename to %s", viewName, viewName));
          });


        if (opts.latestPostfix) {
          var latestViewName = name + this._postfix + opts.latestPostfix
            , latestName = _.takeRight(tables, 1)
            , latestQ = util.format("create view temp_%s as select * from %s", latestViewName, latestName);
          viewP = viewP.then(function () {
            return client.queryAsync(latestQ)
              .then(function() {
                return client.queryAsync("drop view " + latestViewName);
              })
              .then(function () {
                return client.queryAsync(util.format("alter table temp_%s rename to %s", latestViewName,
                  latestViewName));
              });
          });

        }

        return viewP;
      }.bind(this));
    }.bind(this)).return(tables);
  });


});

/**
 * Creates (if necessary) a time series table for a base name, and returns a promise of a time series table name.
 * @param {String} name base name for table. The "static" part of the table name, before any postfixes
 * @return {Promise} promise of time series table name
 * @private
 */
TimeSeriesManager.prototype.tsTableFor = Promise.method(function (name) {

  var tsOpts = this._options[name];

  if(!tsOpts) {
    throw new Error("Couldn't find time series configuration for table " + name);
  }

  var now = Date.now()
    , postf = this._postfix + "_ts_" + ((now - now % (tsOpts.period * 1000)) / 1000).toFixed(0);

  var tsTableName = this._schema + "." + name + postf
      // not using IF NOT EXISTS since we need to know whether a new table was created or not without
      // having to do extra queries
      , ddlStr = util.format("CREATE TABLE %s (%s) %s ", tsTableName, tsOpts.columns.join(',')
      , tsOpts.tableAttrs.join(' '));

  return this._usingPg(function (client) {
    return client.queryAsync(ddlStr)
  }).bind(this).return(tsTableName)
    .tap(function () {
      debug("Created new time series table " + tsTableName);

      return this._listTsTables(name)
        .then(_.partial(this._updateView.bind(this), name)).catch(function (err) {
          error("Error creating view for base name " + name + ": " + err.stack || err);
          return [];
        })
        .then(_.partial(this._pruneTsTables.bind(this), name)).catch(function (err) {
          error("Error pruning time series tables: " + err.stack || err);
          return [];
        });
    })
    .catch(isDuplicate, function () {
      debug("Time series table " + tsTableName + " already exists");
      return this._listTsTables(name)
        .then(_.partial(this._updateView.bind(this), name)).catch(function (err) {
          error("Error creating view for base name " + name + ": " + err.stack || err);
          return [];
        }).return(tsTableName);
    })
    ;
});
